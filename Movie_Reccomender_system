import pandas as pd
import numpy as np
import ast  # for parsing genre strings
from sklearn.preprocessing import MultiLabelBinarizer, MinMaxScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import seaborn as sns
import matplotlib.pyplot as plt

# Load the movie metadata CSV file
df = pd.read_csv("IMDB-Movie-Dataset(2023-1951).csv", low_memory=False)

# Inspect the columns to ensure the correct names
print("Original column names:", df.columns)

# Clean column names to avoid issues with spaces or case sensitivity
df.columns = df.columns.str.strip()  # Remove any leading/trailing spaces
df.columns = df.columns.str.lower()  # Convert all column names to lowercase

# Check column names again after cleaning
print("Cleaned column names:", df.columns)

# Modify the column names to match the dataset's structure
# The new relevant columns are 'movie_name' and 'genre'
df.rename(columns={'movie_name': 'title', 'genre': 'genres'}, inplace=True)

# Check if all necessary columns are available in the dataset
required_columns = ['title', 'genres']
if all(col in df.columns for col in required_columns):
    # Keep only relevant columns for clustering
    movies = df[required_columns].copy()

    # Drop rows with missing values in selected columns
    movies.dropna(subset=['genres'], inplace=True)

    # Parse genres field
    def parse_genres(genre_str):
        """Converts a string of genre dictionaries into a list of genre names."""
        try:
            # If genre_str is already a list, use it directly
            if isinstance(genre_str, str):
                genres = ast.literal_eval(genre_str)
            else:
                genres = genre_str
            return [g['name'] for g in genres if isinstance(g, dict) and 'name' in g]
        except:
            return []

    # Apply the genre parsing function
    movies['genre_list'] = movies['genres'].apply(parse_genres)

    # Encode genres into binary columns
    mlb = MultiLabelBinarizer()
    genre_encoded = mlb.fit_transform(movies['genre_list'])
    genre_df = pd.DataFrame(genre_encoded, columns=mlb.classes_)

    # For simplicity, add some mock numerical features for clustering
    # You may modify this to add real features such as ratings, popularity, etc.
    movies['vote_average'] = np.random.uniform(1, 10, len(movies))  # Simulated 'vote_average'
    movies['popularity'] = np.random.uniform(0, 100, len(movies))  # Simulated 'popularity'

    # Normalize numerical features
    scaler = MinMaxScaler()
    scaled = scaler.fit_transform(movies[['vote_average', 'popularity']])
    scaled_df = pd.DataFrame(scaled, columns=['vote_average', 'popularity'])

    # Combine all features
    final_features = pd.concat([genre_df, scaled_df], axis=1)

    # Determine optimal k using silhouette scores
    inertia_values = []
    silhouette_scores = []
    k_range = range(2, 15)

    for k in k_range:
        kmeans = KMeans(n_clusters=k, random_state=42)
        kmeans.fit(final_features)
        inertia_values.append(kmeans.inertia_)
        silhouette_scores.append(silhouette_score(final_features, kmeans.labels_))

    # Plot silhouette scores
    plt.figure(figsize=(10, 5))
    plt.plot(k_range, silhouette_scores, marker='o', color='purple')
    plt.title('Silhouette Score vs Number of Clusters')
    plt.xlabel('Number of Clusters (k)')
    plt.ylabel('Silhouette Score')
    plt.grid(True)
    plt.show()

    # Choose optimal k (say 8 based on above plot)
    optimal_k = 8
    kmeans = KMeans(n_clusters=optimal_k, random_state=42)
    movies['cluster'] = kmeans.fit_predict(final_features)

    # Cluster visualization
    plt.figure(figsize=(10, 5))
    sns.countplot(data=movies, x='cluster', hue='cluster', palette='Set2', legend=False)
    plt.title('Movie Distribution by Cluster')
    plt.xlabel('Cluster')
    plt.ylabel('Number of Movies')
    plt.show()

    # Recommendation function
    def recommend_movies(title, n=5):
        """Recommend similar movies based on clustering."""
        title = title.strip().lower()  # Normalize input title for case-insensitive matching
        match = movies[movies['title'].str.lower() == title]
        
        if match.empty:
            return f"Movie titled '{title}' not found."
        
        # Get the cluster of the target movie
        cluster_id = match['cluster'].values[0]
        
        # Get all movies from the same cluster, excluding the input movie
        candidates = movies[(movies['cluster'] == cluster_id) & 
                            (movies['title'].str.lower() != title)]
        
        # Return top N based on vote_average and popularity
        return candidates[['title', 'vote_average', 'popularity']].sort_values(
            by=['vote_average', 'popularity'], ascending=False).head(n)

    # Example usage
    print("Recommended movies similar to '3 jawan':")
    print(recommend_movies("Jawan", n=10))
